{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b617bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T09:26:46.890027Z",
     "iopub.status.busy": "2025-06-30T09:26:46.889390Z",
     "iopub.status.idle": "2025-06-30T09:26:48.638632Z",
     "shell.execute_reply": "2025-06-30T09:26:48.637821Z"
    },
    "papermill": {
     "duration": 1.75404,
     "end_time": "2025-06-30T09:26:48.639876",
     "exception": false,
     "start_time": "2025-06-30T09:26:46.885836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/eff_cbam/tensorflow2/default/1/efficientnet_b0_new_model.h5\n",
      "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Late_blight/1e5ba644-efeb-4bd3-b878-a0606cf8a992___RS_Late.B 6272_flipLR.JPG\n",
      "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Late_blight/3dcee9ed-43bb-45a9-8cff-641b3dd62179___RS_Late.B 5324.JPG\n",
      "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Late_blight/532b2c20-d17b-4b3e-a69e-54a6e5343014___GHLB2 Leaf 9004.JPG\n",
      "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Tomato___Late_blight/418ae33c-5f61-4531-82df-8608d82a7a90___RS_Late.B 5574.JPG\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "count=0\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break\n",
    "    if count == 5:  # ensure we stop outer loop too\n",
    "        break\n",
    "            \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f163065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T09:26:48.645487Z",
     "iopub.status.busy": "2025-06-30T09:26:48.644615Z",
     "iopub.status.idle": "2025-06-30T09:27:01.801687Z",
     "shell.execute_reply": "2025-06-30T09:27:01.801049Z"
    },
    "papermill": {
     "duration": 13.161171,
     "end_time": "2025-06-30T09:27:01.803407",
     "exception": false,
     "start_time": "2025-06-30T09:26:48.642236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 09:26:49.928527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751275610.097071      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751275610.147690      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04550c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T09:27:01.809127Z",
     "iopub.status.busy": "2025-06-30T09:27:01.808684Z",
     "iopub.status.idle": "2025-06-30T09:28:16.391235Z",
     "shell.execute_reply": "2025-06-30T09:28:16.390420Z"
    },
    "papermill": {
     "duration": 74.586448,
     "end_time": "2025-06-30T09:28:16.392668",
     "exception": false,
     "start_time": "2025-06-30T09:27:01.806220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 files belonging to 38 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751275690.695296      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17572 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
    "VAL_DIR = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
    "IMAGE_SIZE=(224,224)\n",
    "BATCH_SIZE=32\n",
    "\n",
    "# Normalize images\n",
    "def preprocess(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "    \n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ").map(preprocess).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "class_names=val_ds.class_names\n",
    "val_ds=val_ds.map(preprocess).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58caaa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T09:28:16.397955Z",
     "iopub.status.busy": "2025-06-30T09:28:16.397697Z",
     "iopub.status.idle": "2025-06-30T09:28:16.402986Z",
     "shell.execute_reply": "2025-06-30T09:28:16.402331Z"
    },
    "papermill": {
     "duration": 0.009152,
     "end_time": "2025-06-30T09:28:16.404130",
     "exception": false,
     "start_time": "2025-06-30T09:28:16.394978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import sys\\nsys.path.append('./src')  # Add src directory to path\\n\\nfrom EfficientNet_CBAM_Architecture import EfficientNetB0_custom  # Import your model function\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import sys\n",
    "sys.path.append('./src')  # Add src directory to path\n",
    "\n",
    "from EfficientNet_CBAM_Architecture import EfficientNetB0_custom  # Import your model function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "350303f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T09:28:16.409557Z",
     "iopub.status.busy": "2025-06-30T09:28:16.409169Z",
     "iopub.status.idle": "2025-06-30T09:28:16.430931Z",
     "shell.execute_reply": "2025-06-30T09:28:16.430281Z"
    },
    "papermill": {
     "duration": 0.026009,
     "end_time": "2025-06-30T09:28:16.432205",
     "exception": false,
     "start_time": "2025-06-30T09:28:16.406196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def se_block(inputs, se_ratio=0.25):\n",
    "    filters = inputs.shape[-1]\n",
    "    se_filters = max(1, int(filters * se_ratio))\n",
    "    se = layers.GlobalAveragePooling2D()(inputs)\n",
    "    se = layers.Reshape((1, 1, filters))(se)\n",
    "    se = layers.Conv2D(se_filters, 1, activation='relu')(se)\n",
    "    se = layers.Conv2D(filters, 1, activation='sigmoid')(se)\n",
    "    return layers.Multiply()([inputs, se])\n",
    "    \n",
    "\n",
    "def cbam_block(inputs, reduction_ratio=16):\n",
    "    # Channel Attention\n",
    "    channel_avg = layers.GlobalAveragePooling2D()(inputs)\n",
    "    channel_max = layers.GlobalMaxPooling2D()(inputs)\n",
    "    \n",
    "    shared_dense = tf.keras.Sequential([\n",
    "        layers.Dense(inputs.shape[-1] // reduction_ratio, activation='relu'),\n",
    "        layers.Dense(inputs.shape[-1])\n",
    "    ])\n",
    "\n",
    "    avg_out = shared_dense(channel_avg)\n",
    "    max_out = shared_dense(channel_max)\n",
    "\n",
    "    channel_attention = layers.Add()([avg_out, max_out])\n",
    "    channel_attention = layers.Activation('sigmoid')(channel_attention)\n",
    "    channel_attention = layers.Reshape((1, 1, inputs.shape[-1]))(channel_attention)\n",
    "    x = layers.Multiply()([inputs, channel_attention])\n",
    "\n",
    "    # Spatial Attention using only Keras layers\n",
    "    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(x)\n",
    "    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(x)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "    spatial_attention = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)\n",
    "    x = layers.Multiply()([x, spatial_attention])\n",
    "\n",
    "    return x\n",
    "    \n",
    "\n",
    "def mbconv_block(inputs, out_channels, expansion_factor, kernel_size, strides, se_ratio=0.25):\n",
    "    in_channels = inputs.shape[-1]\n",
    "    x = inputs\n",
    "\n",
    "    # Expansion phase\n",
    "    if expansion_factor != 1:\n",
    "        x = layers.Conv2D(in_channels * expansion_factor, 1, padding='same', use_bias=False)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('swish')(x)\n",
    "\n",
    "    # Depthwise conv\n",
    "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, strides=strides, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    # Squeeze-and-Excitation\n",
    "    x = se_block(x, se_ratio=se_ratio)\n",
    "\n",
    "    # Projection phase\n",
    "    x = layers.Conv2D(out_channels, 1, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Skip connection\n",
    "    if strides == 1 and in_channels == out_channels:\n",
    "        x = layers.Add()([inputs, x])\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def EfficientNetB0_custom(input_shape=(224,224, 3), num_classes=38, dropout_rate=0.2):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Conv2D(32, kernel_size=3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    # MBConv blocks (adapted from official B4 config)\n",
    "    # (repeats, out_channels, kernel_size, strides)\n",
    "    x = mbconv_block(x,out_channels=16,expansion_factor=1,kernel_size=3,strides=1)\n",
    "    block_configs = [\n",
    "        (2, 24, 3, 2),\n",
    "        (2, 40, 5, 2),\n",
    "        (3, 80, 3, 2),\n",
    "        (3, 112, 5, 1),\n",
    "        (4, 192, 5, 2),\n",
    "        (1, 320, 3, 1),\n",
    "    ]\n",
    "\n",
    "    expansion_factor = 6\n",
    "    for repeats, out_channels, kernel_size, strides in block_configs:\n",
    "        for i in range(repeats):\n",
    "            x = mbconv_block(\n",
    "                x,\n",
    "                out_channels=out_channels,\n",
    "                expansion_factor=expansion_factor,\n",
    "                kernel_size=kernel_size,\n",
    "                strides=strides if i == 0 else 1\n",
    "            )\n",
    "\n",
    "    # Head\n",
    "    x = layers.Conv2D(1280, 1, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('swish')(x)\n",
    "\n",
    "    # Convolutional Block Attention Module\n",
    "    x = cbam_block(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1451a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T09:28:16.439810Z",
     "iopub.status.busy": "2025-06-30T09:28:16.439594Z",
     "iopub.status.idle": "2025-06-30T09:28:19.278038Z",
     "shell.execute_reply": "2025-06-30T09:28:19.277403Z"
    },
    "papermill": {
     "duration": 2.843583,
     "end_time": "2025-06-30T09:28:19.279379",
     "exception": false,
     "start_time": "2025-06-30T09:28:16.435796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_e_cbam = EfficientNetB0_custom()\n",
    "model_e_cbam.load_weights('/kaggle/input/eff_cbam/tensorflow2/default/1/efficientnet_b0_new_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45953bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T09:28:19.284586Z",
     "iopub.status.busy": "2025-06-30T09:28:19.284379Z",
     "iopub.status.idle": "2025-06-30T09:30:23.929015Z",
     "shell.execute_reply": "2025-06-30T09:30:23.928210Z"
    },
    "papermill": {
     "duration": 124.650887,
     "end_time": "2025-06-30T09:30:23.932682",
     "exception": false,
     "start_time": "2025-06-30T09:28:19.281795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751275754.168932      63 service.cc:148] XLA service 0x7d7754012130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751275754.169609      63 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1751275754.808011      63 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1751275759.793400      63 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    precision    recall  f1-score   support\n",
      "\n",
      "                                Apple___Apple_scab       0.99      1.00      0.99       504\n",
      "                                 Apple___Black_rot       1.00      1.00      1.00       497\n",
      "                          Apple___Cedar_apple_rust       0.99      0.98      0.99       440\n",
      "                                   Apple___healthy       0.97      1.00      0.98       502\n",
      "                               Blueberry___healthy       1.00      0.98      0.99       454\n",
      "          Cherry_(including_sour)___Powdery_mildew       1.00      0.99      0.99       421\n",
      "                 Cherry_(including_sour)___healthy       1.00      1.00      1.00       456\n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot       0.97      0.96      0.97       410\n",
      "                       Corn_(maize)___Common_rust_       1.00      1.00      1.00       477\n",
      "               Corn_(maize)___Northern_Leaf_Blight       0.97      0.97      0.97       477\n",
      "                            Corn_(maize)___healthy       1.00      1.00      1.00       465\n",
      "                                 Grape___Black_rot       0.99      0.99      0.99       472\n",
      "                      Grape___Esca_(Black_Measles)       1.00      0.99      1.00       480\n",
      "        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       0.99      1.00      0.99       430\n",
      "                                   Grape___healthy       0.99      1.00      1.00       423\n",
      "          Orange___Haunglongbing_(Citrus_greening)       1.00      0.99      1.00       503\n",
      "                            Peach___Bacterial_spot       0.98      1.00      0.99       459\n",
      "                                   Peach___healthy       1.00      0.99      0.99       432\n",
      "                     Pepper,_bell___Bacterial_spot       1.00      0.99      0.99       478\n",
      "                            Pepper,_bell___healthy       0.98      0.98      0.98       497\n",
      "                             Potato___Early_blight       0.99      1.00      1.00       485\n",
      "                              Potato___Late_blight       0.98      1.00      0.99       485\n",
      "                                  Potato___healthy       1.00      0.99      0.99       456\n",
      "                               Raspberry___healthy       0.99      1.00      0.99       445\n",
      "                                 Soybean___healthy       0.99      0.99      0.99       505\n",
      "                           Squash___Powdery_mildew       1.00      1.00      1.00       434\n",
      "                          Strawberry___Leaf_scorch       0.99      1.00      1.00       444\n",
      "                              Strawberry___healthy       1.00      1.00      1.00       456\n",
      "                           Tomato___Bacterial_spot       0.99      0.99      0.99       425\n",
      "                             Tomato___Early_blight       0.97      0.99      0.98       480\n",
      "                              Tomato___Late_blight       0.99      0.95      0.97       463\n",
      "                                Tomato___Leaf_Mold       1.00      1.00      1.00       470\n",
      "                       Tomato___Septoria_leaf_spot       0.98      0.99      0.98       436\n",
      "     Tomato___Spider_mites Two-spotted_spider_mite       0.99      0.99      0.99       435\n",
      "                              Tomato___Target_Spot       0.99      0.95      0.97       457\n",
      "            Tomato___Tomato_Yellow_Leaf_Curl_Virus       1.00      1.00      1.00       490\n",
      "                      Tomato___Tomato_mosaic_virus       1.00      0.99      0.99       448\n",
      "                                  Tomato___healthy       0.98      0.99      0.99       481\n",
      "\n",
      "                                          accuracy                           0.99     17572\n",
      "                                         macro avg       0.99      0.99      0.99     17572\n",
      "                                      weighted avg       0.99      0.99      0.99     17572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "true_labels = []\n",
    "for _, labels in val_ds.unbatch():\n",
    "    true_labels.append(tf.argmax(labels).numpy())\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# 2. Get predicted labels\n",
    "pred_labels = []\n",
    "for images, _ in val_ds:\n",
    "    preds = model_e_cbam.predict(images,verbose=0)\n",
    "    pred_classes = np.argmax(preds, axis=1)\n",
    "    pred_labels.extend(pred_classes)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, target_names=class_names)\n",
    "print(report)\n",
    "# Save to a text file\n",
    "with open(\"classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 389030,
     "modelInstanceId": 368151,
     "sourceId": 453766,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 224.219978,
   "end_time": "2025-06-30T09:30:27.224664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-30T09:26:43.004686",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
